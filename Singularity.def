Bootstrap: docker
From: pytorch/pytorch:2.4.1-cuda12.1-cudnn9-runtime

%environment
    export TRANSFORMERS_OFFLINE=1
    export HF_HUB_OFFLINE=1
    export WANDB_DISABLED=true
    export TOKENIZERS_PARALLELISM=false

    export HF_HOME=/tmp/.hf_cache
    export TRANSFORMERS_CACHE=${HF_HOME}/transformers
    export HF_DATASETS_CACHE=${HF_HOME}/datasets
    export HUGGINGFACE_HUB_CACHE=${HF_HOME}/hub

%files
    requirements.txt /opt/requirements.txt
    download_models_into_container.py /opt/download_models_into_container.py

%post
    set -eux

    apt-get update
    apt-get install -y --no-install-recommends ca-certificates git
    rm -rf /var/lib/apt/lists/*

    python -m pip install --upgrade pip setuptools wheel

    # Force reinstall to remove transformers dev that comes with base image
    python -m pip install --upgrade --force-reinstall \
        certifi requests urllib3 idna charset_normalizer \
        huggingface_hub \
        transformers==4.40.2 \
        datasets==2.21.0 \
        accelerate==0.33.0 \
        sentencepiece protobuf

    # Repo requirements
    python -m pip install -r /opt/requirements.txt

    # Download models into the image (requires internet at build time)
    python /opt/download_models_into_container.py

    # Smoke test
    python - <<'PY'
import sys, torch, transformers, certifi, requests, huggingface_hub
print("python:", sys.version)
print("torch:", torch.__version__)
print("transformers:", transformers.__version__)
print("certifi:", certifi.__version__)
print("requests:", requests.__version__)
print("huggingface_hub:", huggingface_hub.__version__)
PY

%runscript
    exec python "$@"
